## hive

用MR引擎，map，reduce个数怎么确定

```xml
Map
1）数据总大小
2)  blocksize大小
3)  文件个数
4）文件格式(txt,orc则可以分块，若为gzip/snappy则不能利用分布式计算的优势）。
Reduce
1） 自定义设置，但是不是一定有效。如遇到order by等特殊关键字，则受该类关键字制约。
2） 推测估计公式计算：  
 input_map_data_size/hive.exec.reducers.bytes.per.reducer   
 hive.exec.reducers.bytes.per.reducer 该参数默认是64M=67108864

处理特殊字符导入导致行错乱
--hive-drop-import-delims

```

数据治理：atlas

调度 azkaban

分区分桶 ：分区本质是 创建不同目录，分桶本质是分成多个文件（多个reduceTask个）

MR shuffle  spark shuffle flink shuffle之间的区别

## Flink

ck 设置多少是时间插入一次ms

ck 之间最小间隔多少ms

ck 设置检查点模式 exactly_once

ck 设置超时时间 多少ms 保存点在这么多ms内未完成，则会报错

设置 ck 在手动Cancel以后清不清除状态变量。（Delete on cancellation/retain xxxxx）

> Flink相比传统的Spark Streaming区别?   4个点：处理模型、架构模型、时间机制、容错机制
> 处理模型：Flink 是标准的实时处理引擎，基于事件驱动。而 Spark Streaming 是微批（Micro-Batch）的模型。  重点！！！
> 架构模型：Spark Streaming 在运行时的主要角色包括：Master、Worker、Driver、Executor，Flink 在运行时主要包含：Jobmanager、Taskmanager和Slot。
> 时间机制：时间机制SparkStreaming支持的时间机制有限，只支持处理时间。 Flink支持了流处理程序在时间上的三个定义：处理时间、事件时间、注入时间。同时也支持 watermark 机制来处理滞后数据。
> 容错机制：Spark的CheckPoint只能保证数据不丢失，但是无法保证不重复，Flink使用两阶段提交来处理这个问题。
>
>
> Flink的组件栈？
> 四层：
> 部署层，设计到Flink的部署模式。
> RunTime层：提供了Flink的核心计算功能，比如有向无环图的映射、调度等等
> API层：实现了面向流处理和批处理的API
> Libraries层：在API纸上构建的满足特定应用的计算框架，如：机器学习库，CEP等
>
> 你们的Flink集群规模多大？
> 我们公司是Flink On Yarn 7台
> Flink可以支持小集群和TB节点（上千）上运行Flink任务。
>
> Flink的基础编程模型？
> Source - Transformation - dataflows（输出流）
>
> Flink中的分布式缓存吗？如何使用？
> Flink实现的分布式缓存和Hadoop有异曲同工之妙。目的是在本地读取文件，并把他放在 taskmanager 节点中，防止task重复拉取。
> env.registerCachedFile("file:///path/to/exec/file", "localExecFile", true)
>
> 说说Flink中的广播变量，使用时需要注意什么？ 
> BroadcastPartitioner ：广播分区会将上游数据输出到下游算子的每个实例中。适合于大数据集和小数据集做Jion的场景。
> 我们知道Flink是并行的，计算过程可能不在一个Slot中进行，那么有一种情况即：当我们需要访问同一份数据。那么Flink中的广播变量就是为了解决这种情况。我们可以把广播变量理解为是一个公共的共享变量，我们可以把一个dataset 数据集广播出去，然后不同的task在节点上都能够获取到，这个数据在每个节点上只会存在一份。
>
> Flink窗口的划分：
> time-window：有重叠的时间窗口，无重叠。。
> count-window：有重叠的数量窗口，无重叠。。。
>
> Flink中的时间分类：事件时间，处理时间，注册时间
>
> Flink是如果做到容错的？
> Flink实现容错主要靠强大的CheckPoint机制和State机制。Checkpoint 负责定时制作分布式快照、对程序中的状态进行备份；State 用来存储计算过程中的中间状态。
>
> Flink分布式快照的原理是什么？
> Flink的分布式快照是根据Chandy-Lamport算法量身定做的。简单来说就是持续创建分布式数据流及其状态的一致快照。
> 核心思想是在 input source 端插入 barrier，控制 barrier 的同步来实现 snapshot 的备份和 exactly-once 语义。
> 要求 比如说kafka source端需要支持可重置杏，sink端需要支持事务，预提交事务，所有barrier对齐以后，提交状态jobmanager通知提交事务。commit
>
> Flink如何保证精准一次语义的？
> Flink通过实现两阶段提交和状态保存来实现端到端的一致性语义。 分为以下几个步骤：
> 开始事务（beginTransaction）创建一个临时文件夹，来写把数据写入到这个文件夹里面
> 预提交（preCommit）将内存中缓存的数据写入文件并关闭
> 正式提交（commit）将之前写完的临时文件放入目标目录下。这代表着最终的数据会有一些延迟
> 丢弃（abort）丢弃临时文件
> 若失败发生在预提交成功后，正式提交前。可以根据状态来提交预提交的数据，也可删除预提交的数据。
>
> 说说Flink的内存管理？
> Flink 并不是将大量对象存在堆上，而是将对象都序列化到一个预分配的内存块上。此外，Flink大量的使用了堆外内存。如果需要处理的数据超出了内存限制，则会将部分数据存储到硬盘上。Flink 为了直接操作二进制数据实现了自己的序列化框架。
>
> 说说Flink的序列化？
> Java本身自带的序列化和反序列化的功能，但是辅助信息占用空间比较大，在序列化对象时记录了过多的类信息。摒弃了Java原生的序列化方法，以独特的方式处理数据类型和序列化，包含自己的类型描述符，泛型类型提取和类型序列化框架。TypeInformation 是所有类型描述符的基类。
>
> Flink中的window中出现了数据倾斜，你有什么解决办法？
> window产生数据倾斜指的是数据在不同的窗口内堆积的数据量相差过多。本质上产生这种情况的原因是数据源头发送的数据量速度不同导致的。出现这种情况一般通过两种方式来解决：
> 在数据进入窗口前做预聚合
> 重新设计窗口聚合的key
>
> Flink任务延迟高，想解决这个问题，你会如何入手？
> 1、查看checkpoint 是否太频繁，考虑是否可以增大检查点时间
> 2、是否是触发了Flink的反压机制，如果是就需要调整堆内存大小来优化
> 3、增加并发数
>
> Flink的反压和Strom有哪些不同？
> Strom是通过监控来接收队列负载情况，如果超过高水位就将反压信息写入ZK，ZK会通知所有的Wroker进入反压状态。
> Flink的反压是从下游向上游降速，而Strom是从源头降速。
>
> Flink中的算子链？
> 上下游的并行度一致
> 下游节点的入度为1 （也就是说下游节点没有来自其他节点的输入）
> 上下游节点都在同一个 slot group 中（下面会解释 slot group）
> 用户没有禁用 chain
>
> 说说Flink1.9的新特性？
> 支持hive读写、支持UDF
> FlinkSQL TopN和Group By等优化
> CheckPoint和SavePoint针对实际业务场景做了优化
> Flink State查询
>
> 消费kafka数据时，如何清理脏数据？
> 加filter算子
>
> JobManger在集群中扮演了什么角色？
> YARN调度的作用，还有负责确认CheckPoint完成通知、释放资源
>
> Flink中水位线是什么？
> Watermark 是事件时间域中衡量输入完成进度的一种时间概念，假如当前系统的 watermark 为时间 T，那么系统认为所有事件时间小于T的消息都已经到达，即系统任务它不会再接收到事件时间小于 T的消息了。
> - Watermark是一种衡量EventTime进展的机制，可以设定延迟触发。
> - Watermark是用于处理乱序时间的，而正确的处理乱序时间，通常用Watermark机制结合window来实现。
> - 数据流中的Watermark用于表示timestamp小于Watermark的数据都已经到达了，因此window的执行也是由Watermark触发的。
> - Watermark用来让程序自己平衡延迟和结果正确性。
> - 水位线只是衡量数据迟没迟到，进入窗口的范围无关系
>
> 窗口存在的意义是什么？
> 聚合类的处理 Flink可以每来一个消息就处理一次，但是有时我们需要做一些聚合类的处理，例如：在过去的1分钟内有多少用户点击了我们的网页。所以Flink引入了窗口概念。
> 窗口的作用为了周期性的获取数据。就是把传入的原始数据流切分成多个buckets，所有计算都在单一的buckets中进行。窗口（window）就是从 Streaming 到 Batch 的一个桥梁。
> 窗口带来的问题是什么？
> 带来的问题：聚合类处理带来了新的问题，比如乱序/延迟。其解决方案就是 Watermark / allowLateNess / sideOutPut 这一组合拳。
> Watermark 的作用是防止 数据乱序 / 指定时间，内获取不到全部数据。
> allowLateNess 是将窗口关闭时间再延迟一段时间。
> sideOutPut 是最后兜底操作，当指定窗口已经彻底关闭后，就会把所有过期延迟数据放到侧输出流，让用户决定如何处理。
> 总结起来就是说
> Windows -----> Watermark -----> allowLateNess -----> sideOutPut  
> 用Windows把流数据分块处理，用Watermark确定什么时候不再等待更早的数据/触发窗口进行计算，用allowLateNess 将窗口关闭时间再延迟一段时间。用sideOutPut 最后兜底把数据导出到其他地方。
>
> Flink中处理迟到元素？
> 1、抛弃
> 2.发送到侧输出
> 3、等待迟到元素
> 1）Flink中当开窗时，迟到是否与水位线是否没过窗口相关。不开窗时，和水位线相关。
> 2）窗口关闭等待看水位线
> 3）窗口真关闭看水位线 > 窗口结束时间 + 最大允许迟到时间
> 4）当数据来了以后，落在窗口的范围只和事件时间有关，即在开窗时，事件时间决定归属在哪个窗口范围内。
> 5）在开窗时，水位线决定窗口关闭时间。事件时间决定数据所在的窗口范围。
> 6）sideOutputLateData收集的是未能进入窗口的元素。	
>
> 在使用键控状态时使用get获取状态的方式并不是值拷贝，而是获取到一个状态句柄。通过状态句柄可以修改基于相同键中的同一个状态。
>
> keyed State状态编程
> 1）什么函数可以使用getRuntimeContext来定义状态？只有ProcessFunction吗？
> > 只要是RichFunction都可以使用getRuntimeContext来定义状态。
> > ProcessFunction的顶级父类归属于RichFunction。
> > 2）关于无状态算子
> > 比如说普通的map函数是没有状态的，无法从map函数中获取状态，比如getRuntimeContext，但是使用RichMapFunction就可以从map操作中获取状态。
> > 3）mapWithState和flatMapWithState两个带状态的map，其本质就是RichMap和RichFlatMap的简写版。
> > 4）flatMapWithState函数解析：
> > 传入输入类型和状态变量，返回输出类型和状态变量。
> > (IN,state)=>(OUT,state)
> > FlatMapWithState只能定义在keyedStream之后。
> > **mapState、filterState、flatMapState是keyedStream独有。**
> > **Flink 提供了非常灵活的状态 API，可以认为所有的算子都可以有状态。**
> > 5）map/ filter/ flatmap 本来就是无状态的，但是可以通过实现 RichFunction，获取其上下文，从而对状态进行操作。除此之外，还可以使用 flatMapWithState、mapWithState、filterWithState。
> > 6）reduce/ aggregate/ window(window+窗口函数) 本来就是有状态的，由 flink 底层直接管理，当然也可以实现 RichFunction 自定义状态。
> > 7）ProcessFunction 是一类特殊的函数类，是 process 方法的参数，也实现了 RichFunction 接口，是一类特殊的富函数，ProcessFunction如果不定义状态默认是无状态的。
> > 8）DataStream/ KeyedStream/ ConnectedStream/ WindowedStream 等等都可以调用 process 方法，传入的是不同的 ProcessFunction。
> > 9）有状态的流失计算，针对每个算子都是可以去定义的。主要使用RichFunction去实现，RichFunction除了有open和close以外还可以获取运行时上下文。可以将定义好的状态句柄取出来，将状态当做一个本地变量来存取。
> > 10）**比如说reduceFunction聚合函数，系统内部会帮我们保存上一个元素的状态。但是如果我们的逻辑不仅想要上一次的状态还需要额外多的状态就需要我们自己实现RichFunction保存更多的状态，这就是Flink底层帮我们管理的状态。**
>
> 如何开启2PC？
> 在检查点配置开启精准一次
>     //设置检查点模式默认是精准一次
>    env.getCheckpointConfig.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE)
>
>    如何实现端到端的精准一次性？
>    - Flink内部保证：checkPoint
> - Source端：可重新定位数据读取的位置。
> - Sink端：从故障恢复时，数据不会重复写入外部系统，即支持幂等写入或事物写入。
>
> 幂等写入和事务写入简单介绍一下？
> 幂等写入：幂等写入是指一个操作，可以重复执行很多次，但结果只会改变一次，也就是说后面的结果就不起作用了。譬如说redis，ES等KV类型数据库。
> > 幂等在状态恢复写入的过程中会有短暂的数据不一致状态。可以保证最终的状态一致性。
>
> 事务写入：
> 1）预写日志方式
> 把结果数据当成状态保存+批量缓存，然后在收到checkPoint完成的通知时一次性写入Sink系统。
> 每次都需要等到checkPoint完成再去拉取内容，类似批处理按批写入的方式。相当于在Flink和Sink端实现了一个事务，只有FlinkcheckPoint完成Sink端才会去拉取数据。
> DataStream API提供了一个模板类：GenericWriteAheadSink，来实现这种事务型Sink。
> >优点：简单易于实现，由于数据在状态后端已经做好了缓存所以无论什么Sink系统，都可以用这种方式一批搞定。
> >缺点：对Sink端的实时性有影响，如果在预写日志写入到外部系统时如果发生故障二次写入会导致数据重复。
> >2）两阶段提交
> >对于每个checkPoint，Sink任务（外部系统）会启动一个事务，并将接下来所有接收到的数据添加到事务里。
>
> 预写日志和事务写入的区别？
> 预写日志写入是将两次barrier的数据全部缓存起来，等到检查点操作完成在一批写入。
> 两阶段提交是在写入时加入事务，Sink继续写入，如果故障全部撤销。
> 一个checkPoint对应一个事务。 
>
> Flink CEP是什么？
> • 复杂事件处理（Complex Event Processing，CEP）。
> • Flink CEP 是在 Flink 中实现的复杂事件处理（CEP）库。
> • CEP 允许在无休止的事件流中检测事件模式，让我们有机会掌握数据中重要的部分。
> • 一个或多个由简单事件构成的事件流通过一定的规则匹配，然后输出用户想得到的数据 —— 满足则的复杂事件。
> • 处理事件的规则，被叫做 “模式”（Pattern）
>
>  Flink CEP 提供了 Pattern API，用于对输入流数据进行复杂事件规则定义，用来提取符合规则的事件序列。
>
>  

## Phoenix

添加如下配置到 HBase 的 Hregionerver 节点的 hbase-site.xml

配置完成以后给某个字段加索引，注意，例如 如果对name创建的索引，那么查询的时候也必须只查询name字段！

Phoenix索引分全局和局部索引

#### HBase

![image-20200712222535087](C:\Users\swime\AppData\Roaming\Typora\typora-user-images\image-20200712222535087.png)

```
预分区只是为了提前分区，这样就不会造成分区时阻塞了
默认超过10G就要自动拆分，这样影响性能，ROWkey设计不合理。
```





## Flume

为什么你们的是两层flume 为什么你第二层不用kc加hs呢

我用了拦截器 第一次拦截器添加的是topic头来将数据分类

第二层里使用连接器是为了解决23:59分的数据落盘到了第二天！



￼

# 面试术语

您好面试官，我叫郑凯文，毕业于天津大学仁爱学院软件工程系，大三前受到大学教授宣讲启发，决定自学大数据，希望是从事相关工作，实习期寻找一家自动化公司，以为能做到工业物联网项目。后来毕业后去了北京发展，当时一家电商公司正在招收大数据开发工程师，我面试通过以后和团队一起完成相关开发工作，在我进入团队以前采集组件的选型已经定了，我跟着团队也参与了采集通道搭建，后面也参与了数仓的设计搭建工作，完成了部分离线数据分析。后面随着公司业务发展，我们需要实时分析一些指标，特别是用户域和销售转换域，风控域等我们选取框架是sparkstreaming。因为目前我们数仓是属于lamda架构，需要维护实时和离线2个版本，实时数据需要用第二天离线数据校验。我们觉得将我们的数仓转化成实时数仓，而且希望我们的数仓也能快速响应，所以经过我们调研，决定借鉴美团分享的架构搭建一套实时数仓。这个里面核心技术用到flink，所以我们开始对flink进行预研，首先我们是用之前做的实时指标进行flink重构，做成AB线来进行测试。后面也对我们一些业务进行改进，比如检测恶意登录，支付超时。支付到账的双流检测（第三方回执流和用户交易流水流）我在最近的项目中解决的一个问题的是们flinkcheckpoint删除策略不合理导致我们恢复任务报错。